#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é…ç½®æµ‹è¯•è„šæœ¬ - éªŒè¯æ™ºè°±AIé…ç½®æ˜¯å¦æ­£ç¡®
"""

print("ğŸ”§ å¼€å§‹æµ‹è¯•é¡¹ç›®é…ç½®...")

# æµ‹è¯•1ï¼šæ£€æŸ¥ç¯å¢ƒå˜é‡
try:
    from sql_graph.env_utils import ZHIPU_API_KEY
    if ZHIPU_API_KEY:
        print("âœ… ç¯å¢ƒå˜é‡é…ç½®æˆåŠŸï¼ŒZHIPU_API_KEYå·²è¯»å–")
        print(f"   API Keyå‰ç¼€: {ZHIPU_API_KEY[:10]}...")
    else:
        print("âŒ æœªæ‰¾åˆ°ZHIPU_API_KEYï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
        exit(1)
except Exception as e:
    print(f"âŒ ç¯å¢ƒå˜é‡è¯»å–å¤±è´¥: {e}")
    exit(1)

# æµ‹è¯•2ï¼šæ£€æŸ¥LLMé…ç½®
try:
    from sql_graph.my_llm import llm
    print("âœ… LLMé…ç½®æˆåŠŸ")
    print(f"   æ¨¡å‹: {llm.model_name}")
    print(f"   APIåœ°å€: {llm.openai_api_base}")
except Exception as e:
    print(f"âŒ LLMé…ç½®å¤±è´¥: {e}")
    exit(1)

# æµ‹è¯•3ï¼šæµ‹è¯•LLMè¿æ¥
try:
    print("ğŸ” æµ‹è¯•æ™ºè°±AIè¿æ¥...")
    response = llm.invoke("ä½ å¥½ï¼Œè¯·ç®€å•å›å¤ä¸€ä¸‹")
    print(f"âœ… æ™ºè°±AIè¿æ¥æˆåŠŸ!")
    print(f"   å›å¤: {response.content}")
except Exception as e:
    print(f"âŒ æ™ºè°±AIè¿æ¥å¤±è´¥: {e}")
    print("   è¯·æ£€æŸ¥:")
    print("   1. API Keyæ˜¯å¦æ­£ç¡®")
    print("   2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
    print("   3. æ™ºè°±AIè´¦æˆ·ä½™é¢æ˜¯å¦å……è¶³")

print("\nğŸ‰ é…ç½®æµ‹è¯•å®Œæˆ!")